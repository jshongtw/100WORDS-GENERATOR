{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "100WORDS-GENERATOR.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jshongtw/100WORDS-GENERATOR/blob/main/examples/100word.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omMmlBcEhAnZ"
      },
      "source": [
        "!git clone https://github.com/jshongtw/100WORDS-GENERATOR\n",
        "%cd 100WORDS-GENERATOR\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-02MCWbs-1Dy"
      },
      "source": [
        "#@title install google/sentencepiece\n",
        "\n",
        "!git clone https://github.com/google/sentencepiece.git \n",
        "%cd sentencepiece\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake ..\n",
        "!make -j $(nproc)\n",
        "!sudo make install\n",
        "!sudo ldconfig -v\n",
        "%cd ../../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd6uv-H7DlAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c72aa16f-20b0-4c32-ef0b-38ee165f1276"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIV0l_g-i_lK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7200c00-f47d-4090-fc96-eb4b3a66eac4"
      },
      "source": [
        "!head -n 5 /content/drive/MyDrive/100word/test/raw.txt"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "透過十本書寫出心得，認識國文。\r\n",
            "十本書\r\n",
            "閱讀心得\r\n",
            "起初我聽朋友介紹這本書，裡面滿是字，我以為我可能看不了多久就會放棄，沒想到我是越看越起勁，很快地就把著本書看完了。這本書多是簡述他曾在海上的生活，隱晦著人生道理，很開心這次得了優等，下次也會繼續努力。\r\n",
            "本作品參加108學年度全國高級中學閱讀心得比賽獲得甲等，名稱:如果我們擁有自信。\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6T_Tq9O-1Dz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81dbc757-326f-48ec-8af5-4ff791ac279d"
      },
      "source": [
        "!python cut_words.py\n",
        "!python build_tokenizer.py\n",
        "!head -n 20 /content/drive/MyDrive/100word/vocab.txt"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading /content/drive/MyDrive/100word/test/raw.txt\n",
            "total words: 1457721\n",
            "split data into 1 pieces\n",
            "  0% 0/30816 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
            "Loading model from cache /tmp/jieba.cache\n",
            "Loading model cost 0.631 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "100% 30816/30816 [00:10<00:00, 3033.23it/s]\n",
            "[all_task done]\n",
            "dropping /content/drive/MyDrive/100word/test/raw.cut.temp.0.txt\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /content/drive/MyDrive/100word/test/raw.cut.txt\n",
            "  input_format: \n",
            "  model_prefix: spiece\n",
            "  model_type: BPE\n",
            "  vocab_size: 3000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.98\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 2\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(178) LOG(INFO) Loading corpus: /content/drive/MyDrive/100word/test/raw.cut.txt\n",
            "trainer_interface.cc(385) LOG(INFO) Loaded all 30815 sentences\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(466) LOG(INFO) all chars count=2305924\n",
            "trainer_interface.cc(477) LOG(INFO) Done: 98.003% characters are covered.\n",
            "trainer_interface.cc(487) LOG(INFO) Alphabet size=1130\n",
            "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.98003\n",
            "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 30815 sentences.\n",
            "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 30815\n",
            "trainer_interface.cc(537) LOG(INFO) Done! 37023\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=66615 min_freq=95\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6928 size=20 all=32851 active=3405 piece=▁也\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4337 size=40 all=34243 active=4797 piece=▁想\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3059 size=60 all=35684 active=6238 piece=▁感\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2573 size=80 all=36754 active=7308 piece=▁出\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2217 size=100 all=37945 active=8499 piece=▁這個\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2213 min_freq=66\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1778 size=120 all=38742 active=2685 piece=▁課文\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1494 size=140 all=39695 active=3638 piece=▁許\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1375 size=160 all=40289 active=4232 piece=▁記\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1220 size=180 all=41039 active=4982 piece=▁社\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1112 size=200 all=41516 active=5459 piece=▁才\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1102 min_freq=53\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1005 size=220 all=42032 active=2582 piece=▁體\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=940 size=240 all=42589 active=3139 piece=▁找\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=847 size=260 all=43079 active=3629 piece=▁分析\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=790 size=280 all=43480 active=4030 piece=▁我覺\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=738 size=300 all=43777 active=4327 piece=▁字\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=738 min_freq=45\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=676 size=320 all=44120 active=2500 piece=▁筆\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=639 size=340 all=44481 active=2861 piece=▁需要\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=597 size=360 all=44855 active=3235 piece=▁議題\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=567 size=380 all=45092 active=3472 piece=▁運\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=538 size=400 all=45386 active=3766 piece=▁一起\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=536 min_freq=39\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=492 size=420 all=45595 active=2479 piece=▁外\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=464 size=440 all=45924 active=2808 piece=▁;\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=439 size=460 all=46340 active=3224 piece=▁進行\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=420 size=480 all=46635 active=3519 piece=▁相關\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=400 size=500 all=46911 active=3795 piece=▁敘述\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=398 min_freq=35\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=381 size=520 all=47398 active=2828 piece=▁長\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=364 size=540 all=47508 active=2938 piece=▁增加\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=351 size=560 all=47733 active=3163 piece=▁改變\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=338 size=580 all=47939 active=3369 piece=▁工\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=326 size=600 all=48137 active=3567 piece=▁溫\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=326 min_freq=31\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=310 size=620 all=48388 active=2649 piece=▁然\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=304 size=640 all=48593 active=2854 piece=▁引\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=291 size=660 all=48784 active=3045 piece=▁係\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=283 size=680 all=49004 active=3265 piece=▁歸\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=273 size=700 all=49192 active=3453 piece=▁愛情\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=272 min_freq=29\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=265 size=720 all=49317 active=2578 piece=▁幸福\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=259 size=740 all=49403 active=2664 piece=▁這種\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=249 size=760 all=49531 active=2792 piece=嘗試\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=242 size=780 all=49805 active=3066 piece=▁用心\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=234 size=800 all=49982 active=3243 piece=▁尋找\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=234 min_freq=26\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=227 size=820 all=50138 active=2654 piece=▁周\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=223 size=840 all=50288 active=2804 piece=▁之前\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=217 size=860 all=50353 active=2869 piece=▁說明\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=210 size=880 all=50511 active=3027 piece=▁書中\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=202 size=900 all=50756 active=3272 piece=▁現實\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=201 min_freq=24\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=195 size=920 all=50876 active=2653 piece=▁法\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=192 size=940 all=51037 active=2814 piece=▁感到\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=186 size=960 all=51144 active=2921 piece=▁連結\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=181 size=980 all=51286 active=3063 piece=▁感謝\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=176 size=1000 all=51423 active=3200 piece=▁悲\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=176 min_freq=23\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=171 size=1020 all=51559 active=2694 piece=▁採\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=167 size=1040 all=51686 active=2821 piece=▁投稿\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=162 size=1060 all=51813 active=2948 piece=▁制\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=158 size=1080 all=51901 active=3036 piece=▁師說\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=153 size=1100 all=52011 active=3146 piece=▁房間\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=153 min_freq=21\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=147 size=1120 all=52071 active=2659 piece=▁仔\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=144 size=1140 all=52244 active=2832 piece=▁蛋\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=142 size=1160 all=52302 active=2890 piece=▁以後\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=139 size=1180 all=52438 active=3026 piece=▁理念\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=135 size=1200 all=52534 active=3122 piece=▁彼\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=135 min_freq=20\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=133 size=1220 all=52715 active=2806 piece=▁計\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=131 size=1240 all=52882 active=2973 piece=▁本學期\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=128 size=1260 all=52966 active=3057 piece=▁康橋\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=126 size=1280 all=53101 active=3192 piece=▁現今\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=123 size=1300 all=53200 active=3291 piece=▁廣播\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=123 min_freq=19\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=121 size=1320 all=53289 active=2749 piece=▁醫\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=119 size=1340 all=53392 active=2852 piece=▁假\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=116 size=1360 all=53458 active=2918 piece=▁料理\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=112 size=1380 all=53523 active=2983 piece=▁居\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=110 size=1400 all=53668 active=3128 piece=學會\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=110 min_freq=17\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=108 size=1420 all=53772 active=2774 piece=▁很棒\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=106 size=1440 all=53820 active=2822 piece=▁讀物\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=104 size=1460 all=53855 active=2857 piece=▁這堂\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=102 size=1480 all=53904 active=2906 piece=▁兩個\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=100 size=1500 all=54003 active=3005 piece=▁版\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=100 min_freq=17\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=98 size=1520 all=54074 active=2765 piece=▁段落\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=96 size=1540 all=54154 active=2845 piece=貨店\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=94 size=1560 all=54255 active=2946 piece=▁談\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=93 size=1580 all=54422 active=3113 piece=▁日常生活\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=91 size=1600 all=54505 active=3196 piece=▁貨店\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=91 min_freq=16\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=89 size=1620 all=54582 active=2803 piece=▁並在\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=87 size=1640 all=54633 active=2854 piece=▁卡\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=86 size=1660 all=54757 active=2978 piece=▁限\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=85 size=1680 all=54834 active=3055 piece=▁相同\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=83 size=1700 all=54928 active=3149 piece=▁分配\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=83 min_freq=15\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=82 size=1720 all=54948 active=2767 piece=▁女孩\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=81 size=1740 all=55016 active=2835 piece=▁作練習\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=80 size=1760 all=55083 active=2902 piece=▁演出\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=79 size=1780 all=55100 active=2919 piece=▁辦法\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=77 size=1800 all=55125 active=2944 piece=▁半\n",
            "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=77 min_freq=14\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=76 size=1820 all=55220 active=2833 piece=▁以來\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=74 size=1840 all=55244 active=2857 piece=▁摹\n",
            "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=73 size=1860 all=55309 active=2922 piece=▁漁\n",
            "trainer_interface.cc(615) LOG(INFO) Saving model: spiece.model\n",
            "trainer_interface.cc(626) LOG(INFO) Saving vocabs: spiece.vocab\n",
            "head: cannot open '/content/drive/MyDrive/100word/vocab.txt' for reading: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sw50oOIi-Be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c31e82-e6c3-4bc7-a99f-fa91f2dc6b68"
      },
      "source": [
        "!python predata.py\n",
        "!python train.py --epochs 50"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-20 06:13:19.657108: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "reading /content/drive/MyDrive/100word/test/raw.txt\n",
            "total words: 1457721\n",
            "merging data\n",
            "merged\n",
            "num of task:  1\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "  0% 0/973 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3225 > 64). Running this sequence through the model will result in indexing errors\n",
            "100% 973/973 [00:06<00:00, 144.84it/s]\n",
            "assert 0 with 95802\n",
            "[all_task done]\n",
            "2021-07-20 06:13:29.805207: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-20 06:13:31.464092: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-20 06:13:31.492148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 06:13:31.492840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-20 06:13:31.492884: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-20 06:13:31.495689: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-20 06:13:31.495758: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-20 06:13:31.497456: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-20 06:13:31.497884: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-20 06:13:31.499753: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-20 06:13:31.500509: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-20 06:13:31.500722: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-20 06:13:31.500884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 06:13:31.501555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 06:13:31.502108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-20 06:13:31.502412: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-20 06:13:31.502610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 06:13:31.503155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-20 06:13:31.503235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 06:13:31.503793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 06:13:31.504307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-20 06:13:31.504354: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-20 06:13:32.037574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-20 06:13:32.037635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-07-20 06:13:32.037652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-07-20 06:13:32.037839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 06:13:32.038491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 06:13:32.039118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 06:13:32.039714: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-20 06:13:32.039763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "loading /content/drive/MyDrive/100word/test/data_0.pickle\n",
            "(95801, 63) (95801, 63) int64 int64\n",
            "2021-07-20 06:13:32.321113: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "2021-07-20 06:13:32.361429: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-20 06:13:32.882562: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/100word/models/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "INFO:absl:using Adamw optimizer\n",
            "INFO:absl:gradient_clip_norm=1.000000\n",
            "2021-07-20 06:13:33.380854: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
            "2021-07-20 06:13:33.380904: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
            "2021-07-20 06:13:33.380945: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\n",
            "2021-07-20 06:13:33.381854: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcupti.so.11.0\n",
            "2021-07-20 06:13:33.604511: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
            "2021-07-20 06:13:33.604700: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
            "2021-07-20 06:13:33.966326: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT64\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 63\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 63\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "2021-07-20 06:13:34.044569: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-07-20 06:13:34.044994: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000175000 Hz\n",
            "Epoch 1/50\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "   1/1000 [..............................] - ETA: 3:32:07 - loss: 7.6381 - accuracy: 0.00602021-07-20 06:13:46.929674: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
            "2021-07-20 06:13:46.929715: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
            "   2/1000 [..............................] - ETA: 7:23 - loss: 7.7167 - accuracy: 0.0069   2021-07-20 06:13:47.245028: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
            "2021-07-20 06:13:47.245982: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
            "2021-07-20 06:13:47.398422: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 1116 callback api events and 1113 activity events. \n",
            "2021-07-20 06:13:47.414840: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
            "2021-07-20 06:13:47.446118: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /content/drive/MyDrive/100word/models//logs/train/plugins/profile/2021_07_20_06_13_47\n",
            "2021-07-20 06:13:47.473098: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /content/drive/MyDrive/100word/models//logs/train/plugins/profile/2021_07_20_06_13_47/defcbea88b08.trace.json.gz\n",
            "2021-07-20 06:13:47.516294: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /content/drive/MyDrive/100word/models//logs/train/plugins/profile/2021_07_20_06_13_47\n",
            "2021-07-20 06:13:47.525262: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /content/drive/MyDrive/100word/models//logs/train/plugins/profile/2021_07_20_06_13_47/defcbea88b08.memory_profile.json.gz\n",
            "2021-07-20 06:13:47.543772: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /content/drive/MyDrive/100word/models//logs/train/plugins/profile/2021_07_20_06_13_47Dumped tool data for xplane.pb to /content/drive/MyDrive/100word/models//logs/train/plugins/profile/2021_07_20_06_13_47/defcbea88b08.xplane.pb\n",
            "Dumped tool data for overview_page.pb to /content/drive/MyDrive/100word/models//logs/train/plugins/profile/2021_07_20_06_13_47/defcbea88b08.overview_page.pb\n",
            "Dumped tool data for input_pipeline.pb to /content/drive/MyDrive/100word/models//logs/train/plugins/profile/2021_07_20_06_13_47/defcbea88b08.input_pipeline.pb\n",
            "Dumped tool data for tensorflow_stats.pb to /content/drive/MyDrive/100word/models//logs/train/plugins/profile/2021_07_20_06_13_47/defcbea88b08.tensorflow_stats.pb\n",
            "Dumped tool data for kernel_stats.pb to /content/drive/MyDrive/100word/models//logs/train/plugins/profile/2021_07_20_06_13_47/defcbea88b08.kernel_stats.pb\n",
            "\n",
            "   6/1000 [..............................] - ETA: 3:18 - loss: 7.6438 - accuracy: 0.0089WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0577s vs `on_train_batch_begin` time: 0.1693s). Check your callbacks.\n",
            "WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0577s vs `on_train_batch_begin` time: 0.1693s). Check your callbacks.\n",
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0577s vs `on_train_batch_end` time: 0.0781s). Check your callbacks.\n",
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0577s vs `on_train_batch_end` time: 0.0781s). Check your callbacks.\n",
            "1000/1000 [==============================] - 58s 45ms/step - loss: 5.2821 - accuracy: 0.1557\n",
            "Epoch 2/50\n",
            "1000/1000 [==============================] - 49s 46ms/step - loss: 4.3725 - accuracy: 0.2346\n",
            "Epoch 3/50\n",
            "1000/1000 [==============================] - 50s 47ms/step - loss: 4.0882 - accuracy: 0.2643\n",
            "Epoch 4/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.9167 - accuracy: 0.2846\n",
            "Epoch 5/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.7937 - accuracy: 0.2980\n",
            "Epoch 6/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.6766 - accuracy: 0.3132\n",
            "Epoch 7/50\n",
            "1000/1000 [==============================] - 52s 47ms/step - loss: 3.6048 - accuracy: 0.3213\n",
            "Epoch 8/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.5381 - accuracy: 0.3293\n",
            "Epoch 9/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.4801 - accuracy: 0.3369\n",
            "Epoch 10/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.4338 - accuracy: 0.3413\n",
            "Epoch 11/50\n",
            "1000/1000 [==============================] - 50s 47ms/step - loss: 3.3850 - accuracy: 0.3483\n",
            "Epoch 12/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.3590 - accuracy: 0.3498\n",
            "Epoch 13/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.3020 - accuracy: 0.3581\n",
            "Epoch 14/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.2657 - accuracy: 0.3627\n",
            "Epoch 15/50\n",
            "1000/1000 [==============================] - 50s 47ms/step - loss: 3.2327 - accuracy: 0.3671\n",
            "Epoch 16/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.1709 - accuracy: 0.3752\n",
            "Epoch 17/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.1461 - accuracy: 0.3787\n",
            "Epoch 18/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.1045 - accuracy: 0.3838\n",
            "Epoch 19/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.0670 - accuracy: 0.3894\n",
            "Epoch 20/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.0550 - accuracy: 0.3904\n",
            "Epoch 21/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.0280 - accuracy: 0.3934\n",
            "Epoch 22/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 3.0113 - accuracy: 0.3967\n",
            "Epoch 23/50\n",
            "1000/1000 [==============================] - 51s 47ms/step - loss: 3.0020 - accuracy: 0.3970\n",
            "Epoch 24/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.9909 - accuracy: 0.3978\n",
            "Epoch 25/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.9486 - accuracy: 0.4045\n",
            "Epoch 26/50\n",
            "1000/1000 [==============================] - 50s 47ms/step - loss: 2.9396 - accuracy: 0.4050\n",
            "Epoch 27/50\n",
            "1000/1000 [==============================] - 50s 47ms/step - loss: 2.8932 - accuracy: 0.4121\n",
            "Epoch 28/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.8743 - accuracy: 0.4154\n",
            "Epoch 29/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.8439 - accuracy: 0.4185\n",
            "Epoch 30/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.8035 - accuracy: 0.4260\n",
            "Epoch 31/50\n",
            "1000/1000 [==============================] - 50s 47ms/step - loss: 2.7933 - accuracy: 0.4263\n",
            "Epoch 32/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.7817 - accuracy: 0.4284\n",
            "Epoch 33/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.7681 - accuracy: 0.4296\n",
            "Epoch 34/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.7678 - accuracy: 0.4296\n",
            "Epoch 35/50\n",
            "1000/1000 [==============================] - 50s 47ms/step - loss: 2.7581 - accuracy: 0.4306\n",
            "Epoch 36/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.7419 - accuracy: 0.4330\n",
            "Epoch 37/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.7349 - accuracy: 0.4354\n",
            "Epoch 38/50\n",
            "1000/1000 [==============================] - 51s 47ms/step - loss: 2.7183 - accuracy: 0.4367\n",
            "Epoch 39/50\n",
            "1000/1000 [==============================] - 50s 47ms/step - loss: 2.6878 - accuracy: 0.4404\n",
            "Epoch 40/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.6763 - accuracy: 0.4427\n",
            "Epoch 41/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.6401 - accuracy: 0.4494\n",
            "Epoch 42/50\n",
            "1000/1000 [==============================] - 50s 47ms/step - loss: 2.6435 - accuracy: 0.4488\n",
            "Epoch 43/50\n",
            "1000/1000 [==============================] - 50s 47ms/step - loss: 2.6365 - accuracy: 0.4492\n",
            "Epoch 44/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.6246 - accuracy: 0.4511\n",
            "Epoch 45/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.5962 - accuracy: 0.4561\n",
            "Epoch 46/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.6191 - accuracy: 0.4528\n",
            "Epoch 47/50\n",
            "1000/1000 [==============================] - 50s 47ms/step - loss: 2.6056 - accuracy: 0.4546\n",
            "Epoch 48/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.6063 - accuracy: 0.4538\n",
            "Epoch 49/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.6088 - accuracy: 0.4535\n",
            "Epoch 50/50\n",
            "1000/1000 [==============================] - 49s 47ms/step - loss: 2.6075 - accuracy: 0.4532\n",
            "total train time 2596.171402454376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSFuK-tgs9xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f3409b-8eb1-4a09-80fc-8394afa8c07b"
      },
      "source": [
        "!python predict.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-20 07:03:17.370059: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "2021-07-20 07:03:19.058901: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-20 07:03:19.088826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 07:03:19.089444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-20 07:03:19.089494: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-20 07:03:19.092176: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-20 07:03:19.092256: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-20 07:03:19.093887: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-20 07:03:19.094275: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-20 07:03:19.096176: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-20 07:03:19.096795: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-20 07:03:19.096991: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-20 07:03:19.097108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 07:03:19.097732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 07:03:19.098262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-20 07:03:19.098567: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-20 07:03:19.098814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 07:03:19.099375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-20 07:03:19.099474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 07:03:19.100308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 07:03:19.101074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-20 07:03:19.101165: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-20 07:03:19.615000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-20 07:03:19.615059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-07-20 07:03:19.615076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-07-20 07:03:19.615303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 07:03:19.616061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 07:03:19.616741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-20 07:03:19.617319: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-20 07:03:19.617364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2021-07-20 07:03:19.630921: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "2021-07-20 07:03:19.676234: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-20 07:03:20.190035: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/100word/models/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "INFO:absl:using Adamw optimizer\n",
            "INFO:absl:gradient_clip_norm=1.000000\n",
            "[{'generated_text': '我最喜歡物理學的一首歌:這個活動很有意義,可能沒有這麼多的特色,我覺得我們可以很快的找到歌詞來做比較容易理解我們的這次的活動主要讓了解自我的一題一題題詩寫了解到的主題的是選了樂府,讓自古想古詩讓我們去探歌'}]\n",
            "[{'generated_text': '我最喜歡物理學,我最喜歡的就是'}]\n",
            "[{'generated_text': '我最喜歡物理學,但是我最喜歡的就是'}]\n",
            "[{'generated_text': '我最喜歡物理學,因為我喜歡的物理學,所以我很喜歡這個物理學,所以我很喜歡這個物理學,所以我很喜歡這個物理學,因為我喜歡這個物理學,所以我很喜歡畫我很喜歡這個球色的色,因為我很喜歡色,因喜歡色'}]\n",
            "[{'generated_text': '我最喜歡物理學,因為我喜歡的物理學,所以我很喜歡這個物理學,所以我很喜歡這個物理學,所以我很喜歡這個物理學,因為我喜歡這個物理學,所以我很喜歡畫我很喜歡這個球色的色,因為我很喜歡色,因喜歡色'}]\n",
            "[{'generated_text': '我最喜歡物理學,因為我喜歡的物理學,所以我很喜歡這個物理學,所以我很喜歡這個物理學,所以我很喜歡這個物理學,因為我喜歡這個物理學,所以我很喜歡畫我很喜歡這個球色的色,因為我很喜歡色,因喜歡色'}]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}